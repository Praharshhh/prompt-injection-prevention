<!-- Use this file to provide workspace-specific custom instructions to Copilot. For more details, visit https://code.visualstudio.com/docs/copilot/copilot-customization#_use-a-githubcopilotinstructionsmd-file -->

This is a Python project for building an AI/ML model to detect prompt injection attacks in LLMs.

Key components:
- Transformer-based models for text classification
- Feature engineering for prompt analysis
- Model training and evaluation pipeline
- Production deployment capabilities

Focus on:
- Security best practices
- Model robustness and reliability
- Efficient data processing
- Clear documentation and type hints
